{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset  \n",
    "For the dataset, we use [Sentiment140](http://help.sentiment140.com/for-students)  \n",
    "And we will build a simple model that decides positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "import zipfile\n",
    "import urllib.request\n",
    "if not os.path.exists(\"dataset\"):\n",
    "    os.makedirs(\"dataset\")\n",
    "if not os.path.exists(os.path.join(\"dataset\", \"sentiment140\")):\n",
    "    urllib.request.urlretrieve(\"http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\", os.path.join(\"dataset\", \"sentiment140.zip\"))\n",
    "    with zipfile.ZipFile(os.path.join(\"dataset\", \"sentiment140.zip\"), 'r') as inFile:\n",
    "        inFile.extractall(os.path.join(\"dataset\", \"sentiment140\"))\n",
    "    os.remove(os.path.join(\"dataset\", \"sentiment140.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_TRAINING = os.path.join(\"dataset\", \"sentiment140\", \"training.1600000.processed.noemoticon.csv\")\n",
    "FILE_PATH_PROCESSED = os.path.join(\"dataset\", \"sentiment140\", \"processed.csv\")\n",
    "FILE_PATH_TEST_NO_USE = os.path.join(\"dataset\", \"sentiment140\", \"testdata.manual.2009.06.14.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing  \n",
    "1. remove extra space, characters, and process @words  \n",
    "2. pad the sentences  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FILE_PATH_PROCESSED):\n",
    "    tmp = pd.read_csv(FILE_PATH_TRAINING, names=[\"Target\", \"ID\", \"Date\", \"QueryInfo\", \"UserName\", \"Text\"], encoding=\"latin-1\")\n",
    "    tmp.to_csv(FILE_PATH_PROCESSED, encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(FILE_PATH_PROCESSED, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000,) (1600000,)\n"
     ]
    }
   ],
   "source": [
    "# select the needed columns\n",
    "X_train = training_data[\"Text\"].copy()\n",
    "y_train = training_data[\"Target\"].copy()\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1    is upset that he can't update his Facebook by ...\n",
       "2    @Kenichan I dived many times for the ball. Man...\n",
       "3      my whole body feels itchy and like its on fire \n",
       "4    @nationwideclass no, it's not behaving at all....\n",
       "5                        @Kwesidei not the whole crew \n",
       "6                                          Need a hug \n",
       "7    @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8                 @Tatiana_K nope they didn't have it \n",
       "9                            @twittera que me muera ? \n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "ch_range = list(range(97, 123)) + list(range(65, 91)) + [ord(' '), ord('\\'')]\n",
    "def process_str(raw_string):\n",
    "    global ch_range\n",
    "    global stemmer\n",
    "    # first remove url, @username, etc\n",
    "    raw_string = re.sub(r\"@([A-Z]|[a-z]|[0-9]|_)+\", \"\", raw_string)\n",
    "    raw_string = re.sub(r\"(http|https)://([A-Z]|[a-z]|[0-9]|/|\\.)+\", \"\", raw_string)\n",
    "    # remove characters other than [a-z][A-Z][0-9]['!?] or empty space\n",
    "    new_string = \"\".join([ch.lower() if ord(ch) in ch_range else ' ' for ch in list(raw_string)])\n",
    "    # remove extra space, and also convert plural form to singular\n",
    "    new_string = new_string.strip()\n",
    "    new_string = \" \".join([stemmer.stem(word) for word in new_string.split()])\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awww that a bummer you shoulda got david carr ...\n",
       "1    is upset that he can't updat his facebook by t...\n",
       "2    i dive mani time for the ball manag to save th...\n",
       "3         my whole bodi feel itchi and like it on fire\n",
       "4    no it not behav at all i'm mad whi am i here b...\n",
       "5                                   not the whole crew\n",
       "6                                           need a hug\n",
       "7    hey long time no see yes rain a bit onli a bit...\n",
       "8                             nope they didn't have it\n",
       "9                                         que me muera\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed = X_train.apply(process_str)\n",
    "X_train_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty string rows\n",
    "index_to_remove = X_train_processed[X_train_processed == \"\"].index\n",
    "X_train_processed = X_train_processed.drop(index_to_remove)\n",
    "y_train = y_train.drop(index_to_remove)\n",
    "X_train_processed = X_train_processed.reset_index()\n",
    "y_train = y_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww that a bummer you shoulda got david carr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is upset that he can't updat his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i dive mani time for the ball manag to save th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>my whole bodi feel itchi and like it on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>no it not behav at all i'm mad whi am i here b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>hey long time no see yes rain a bit onli a bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>que me muera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               Text\n",
       "0      0  awww that a bummer you shoulda got david carr ...\n",
       "1      1  is upset that he can't updat his facebook by t...\n",
       "2      2  i dive mani time for the ball manag to save th...\n",
       "3      3       my whole bodi feel itchi and like it on fire\n",
       "4      4  no it not behav at all i'm mad whi am i here b...\n",
       "5      5                                 not the whole crew\n",
       "6      6                                         need a hug\n",
       "7      7  hey long time no see yes rain a bit onli a bit...\n",
       "8      8                           nope they didn't have it\n",
       "9      9                                       que me muera"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Target\n",
       "0      0       0\n",
       "1      1       0\n",
       "2      2       0\n",
       "3      3       0\n",
       "4      4       0\n",
       "5      5       0\n",
       "6      6       0\n",
       "7      7       0\n",
       "8      8       0\n",
       "9      9       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = X_train_processed[\"Text\"]\n",
    "y_train = y_train[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.DataFrame(np.array([y_train, X_train_processed]).T, columns=[\"Target\", \"Text\"])\n",
    "processed_data.to_csv(os.path.join(\"dataset\", \"sentiment140\", \"final.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_MAXLEN = 80\n",
    "TOKENIZE_MAXWORDS = 30\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=TOKENIZE_MAXWORDS)\n",
    "tokenizer.fit_on_texts(X_train_processed)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_processed)\n",
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, padding=\"post\", maxlen=PAD_MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225642"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "TOKEN_VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596353, 80)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  4,  8, 12, 26,  2,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 9, 13,  5,  7,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596353,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_processed = y_train.replace(4, 1).to_numpy().ravel()\n",
    "y_train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 14 11 19 16 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [ 1 25 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [ 1  5  1 29  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [ 4 26  4 12  4 19 23  5 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [24  3  1  2 13 21 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# shuffle the dataset once to prepare for training\n",
    "index_permut = np.random.permutation(len(y_train_processed))\n",
    "X_train_final = np.array(X_train_pad)[index_permut]\n",
    "y_train_final = np.array(y_train_processed)[index_permut]\n",
    "print(X_train_final[:5])\n",
    "print(y_train_final[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"dataset\", \"sentiment140\", \"data.pickle\"), \"wb\") as outFile:\n",
    "    pickle.dump([X_train_final, y_train_final, tokenizer], outFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
